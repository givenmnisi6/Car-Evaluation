# -*- coding: utf-8 -*-
"""Car Evaluation Database.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YnEaGC5cItedbkM3VrKZGzqpMOJh_rZ5
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from imblearn.over_sampling import RandomOverSampler
from sklearn.compose import ColumnTransformer, make_column_transformer
from sklearn.metrics import roc_curve, auc
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, roc_auc_score, auc

"""# Car Evaluation"""

#Renaming the header column names

columnName  = ["buying", "maintenance", "doors", "persons", "luggage_boot", "safety", "class"]

#Opening the dataset as csv and assigning the labels to the columns
df = pd.read_csv("car.data", names=columnName)

#Changing the data to numbers
#le = preprocessing.LabelEncoder()
#df = df.apply(le.fit_transform)

df.head()

#Converting our classes into numbers so that the computer understands - ['unacc', 'acc', 'vgood', 'good']
cMappings = {"unacc": 0, "acc": 1, "vgood": 2, "good": 3}
df['class'] = df['class'].replace(cMappings)

df.head()

"""#Train, validation, test datasets

"""

#np.split - splitting the dataset
#60%        : training data
#60 - 80%   : validating data
#80 - 100%  : testing data
train, valid, test = np.split(df.sample(frac=1), [int(0.6*len(df)), int(0.8*len(df))])

#Scaling the dataset - Normalizing the features (standardizing)
def scaleDataset(dataframe):
    # x - all columns except the last one
    # y - last column
    x = dataframe[dataframe.columns[:-1]]
    y = dataframe[dataframe.columns[-1]]

    # One-hot encode categorical columns - Converting it to binary for the computer to understand
    categoricalColumn = ['buying', 'maintenance', 'doors', 'persons', 'luggage_boot', 'safety']
    x = pd.get_dummies(x, columns=categoricalColumn)

    # Convert y to numeric using class mapping and replacing the y's
    class_mapping = {"unacc": 0, "acc": 1, "vgood": 2, "good": 3}
    y = y.replace(class_mapping)

    scaler = StandardScaler()
    # Fitting x, transforming all the values and converting x to numpy array using .values
    x = scaler.fit_transform(x.values)

    # Stacking the array side by side and convert y to numpy array using .values
    data = np.hstack((x, np.reshape(y.values, (-1, 1))))

    return data, x, y

train, x_train, y_train = scaleDataset(train)
valid, x_valid, y_valid = scaleDataset(valid)
test, x_test, y_test = scaleDataset(test)

#Checking the number of classes

print(len(train[train["class"]==0]))
print(len(train[train["class"]==1]))
print(len(train[train["class"]==2]))
print(len(train[train["class"]==3]))

"""# Notes

*   If a model avoids a lot of mistakes in predicting bananas as apples - **precision**
*   If a model avoids a lot of mistakes in predicting apples as bananas - **recall**

*   **f1-score** takes into consideration both precision and recall

# kNN Model
"""

# Setting the neighbors parameter - weights
knn_model = KNeighborsClassifier(n_neighbors = 8)
#Fitting all the model
knn_model.fit(x_train, y_train)

#Getting all the predictions
y_prediction = knn_model.predict(x_test)

print(classification_report(y_test, y_prediction))

"""# ROC Curve"""

# Plot ROC curve for kNN
y_probabilities = knn_model.predict_proba(x_test)
roc_auc_knn = roc_auc_score(y_test, y_probabilities, multi_class='ovr')

print("AUC for k-Nearest Neighbors (kNN):", roc_auc_knn)

fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(4):  # Assuming 4 classes (0, 1, 2, 3)
    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_probabilities[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot the ROC curves for all classes
plt.figure(figsize=(8, 6))
colors = ['red', 'orange', 'green', 'yellow']
for i in range(4):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve - kNN')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

"""# SVM"""

from sklearn.svm import SVC

#For calculating the AUC and ROC
svm_model = SVC(probability = True)
svm_model = svm_model.fit(x_train, y_train)

y_prediction = svm_model.predict(x_test)
print(classification_report(y_test, y_prediction))

"""# ROC Curve for SVM"""

y_probabilities = svm_model.predict_proba(x_test)
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(4):  # Assuming 4 classes (0, 1, 2, 3)
    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_probabilities[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot the ROC curves for all classes
plt.figure(figsize=(8, 6))
colors = ['red', 'orange', 'green', 'yellow']
for i in range(4):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve - SVM')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()

roc_auc_svm = roc_auc_score(y_test, y_probabilities, multi_class='ovr')
print("AUC for SVM:", roc_auc_svm)

"""# Random Forest"""

from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(x_train, y_train)

y_prediction = rf_model.predict(x_test)
print(classification_report(y_test, y_prediction))

y_probabilities = rf_model.predict_proba(x_test)
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(4):  # Assuming 4 classes (0, 1, 2, 3)
    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_probabilities[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot the ROC curves for all classes
plt.figure(figsize=(8, 6))
colors = ['red', 'orange', 'green', 'yellow']
for i in range(4):
    plt.plot(fpr[i], tpr[i], color=colors[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('Receiver Operating Characteristic (ROC) Curve - Random Forest')
plt.legend(loc='lower right')
plt.grid(True)
plt.show()


roc_auc_rf = roc_auc_score(y_test, y_probabilities, multi_class='ovr')

print("ROC AUC score for Random Forest:", roc_auc_rf)